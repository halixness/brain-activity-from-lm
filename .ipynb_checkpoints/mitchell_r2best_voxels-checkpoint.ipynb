{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic features as word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len_line = 5\n",
    "N_SEMANTIC_FEATURES = 25\n",
    "semantic_features = {}\n",
    "\n",
    "def dump_mitchell_web_semantic_features(raw_file = os.path.join(\"data\",\"mitchell_semantic_raw.txt\")):\n",
    "    with open(raw_file, \"r\") as datafile:\n",
    "        lines = datafile.readlines()\n",
    "        word = None\n",
    "\n",
    "        for line in lines:\n",
    "\n",
    "            # Skip empty\n",
    "            if len(line) >= min_len_line:\n",
    "\n",
    "                # New feature\n",
    "                if \"Features for\" in line:\n",
    "\n",
    "                    # Discard invalid ones (once fully parsed)\n",
    "                    if word and len(semantic_features[word]['features']) < N_SEMANTIC_FEATURES: del semantic_features[word] \n",
    "                        \n",
    "                    word = line.split(\"<a name=\\\"\")[1].split(\"\\\"\")[0]\n",
    "                    semantic_features[word] = { \"features\": [], \"values\": []}\n",
    "\n",
    "                elif word:\n",
    "                    feature_name = line.split(\"(\")[0]\n",
    "                    val = float(line.split(\"(\")[1].split(\")\")[0])\n",
    "                    semantic_features[word][\"features\"].append(feature_name)\n",
    "                    semantic_features[word][\"values\"].append(val)\n",
    "\n",
    "    # Save to file\n",
    "    #with open(os.path.join('data', 'mitchell_semantic_features.json'), 'w') as fp:\n",
    "    #    json.dump(semantic_features, fp)\n",
    "\n",
    "    return semantic_features\n",
    "\n",
    "\n",
    "def load_sorted_semantic_features(file = os.path.join(\"data\",\"mitchell_semantic_features.json\")):\n",
    "    with open(file) as f:\n",
    "        semantic_features = json.load(f)\n",
    "        for word in semantic_features.keys():\n",
    "            # Sort all features\n",
    "            sorted_features = sorted(enumerate(semantic_features[word][\"features\"]), key=lambda x:x[1])\n",
    "            sorted_indices = [i[0] for i in sorted_features]\n",
    "            sorted_values = [semantic_features[word][\"values\"][i] for i in sorted_indices]\n",
    "\n",
    "            # Re-store them\n",
    "            semantic_features[word][\"features\"] = [x[1] for x in sorted_features]\n",
    "            semantic_features[word][\"values\"] = sorted_values\n",
    "            break\n",
    "\n",
    "    return semantic_features\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_features = load_sorted_semantic_features()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mitchell_original_data(subject = 1, random_voxels = None):\n",
    "    mdata = scipy.io.loadmat(os.path.join(\"data\", \"mitchell\", f\"mitchell_subject_{subject}.mat\"))\n",
    "    subject_data = {}\n",
    "\n",
    "    # 6 x 60 trials\n",
    "    for i in range(mdata[\"data\"][:].shape[0]):\n",
    "        cond, cond_number, word, word_number, epoch = [x[0] for x in mdata[\"info\"][0][i]]\n",
    "\n",
    "        # Set trial data\n",
    "        if epoch[0] not in subject_data: subject_data[epoch[0]] = {}\n",
    "\n",
    "        if random_voxels:\n",
    "            random_voxels_idx = np.random.choice(mdata[\"data\"][i][0][0].shape[0], random_voxels)\n",
    "            subject_data[epoch[0]][word] = mdata[\"data\"][i][0][0][random_voxels_idx]\n",
    "        else: subject_data[epoch[0]][word] = mdata[\"data\"][i][0][0]\n",
    "\n",
    "    return subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "fmriData = get_mitchell_original_data(subject=1)[epoch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosim(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxels_compute_fold_accuracy(predictors, X_test, y_test, selected_voxels):\n",
    "\n",
    "    true_positives = []\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        pi = np.array([predictor.predict([X_test[i]])[0] for x, predictor in enumerate(predictors) if x in selected_voxels]).flatten()\n",
    "        best_sample_match = np.argmax([cosim(pi, y_test[j, selected_voxels]) for j in range(y_test.shape[0])])\n",
    "    \n",
    "        true_positives.append(int(best_sample_match == i)) # ground truth is aligned with the sample by index, it should match\n",
    "\n",
    "    return np.mean(true_positives)\n",
    "\n",
    "\n",
    "def regressor_compute_fold_accuracy(predictors, X_test, y_test):\n",
    "\n",
    "    true_positives = []\n",
    "\n",
    "    # For each sample prediction -> cosine similarity with all truth images\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        pi = predictors.predict([X_test[i]])\n",
    "        best_sample_match = np.argmax([cosim(pi, y_test[j]) for j in range(y_test.shape[0])])\n",
    "\n",
    "        true_positives.append(int(best_sample_match == i)) # ground truth is aligned with the sample by index, it should match\n",
    "\n",
    "    return np.mean(true_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2, 21764)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_folds = 30\n",
    "n_samples = len(semantic_features.keys())\n",
    "\n",
    "assert n_samples % k_folds == 0, \"Number of folds must divide the samples in equal parts. Choose a valid multiplier.\"\n",
    "\n",
    "samples_per_fold = (n_samples // k_folds)\n",
    "n_voxels = fmriData[\"bell\"].shape[0]\n",
    "VOXELWISE_ACC_THRESHOLD = 0.2\n",
    "n_samples, samples_per_fold, n_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len = len(semantic_features[\"bell\"][\"values\"])\n",
    "# we need to remove the correct one, but the index changes for each word. \n",
    "# that's why it performs badly! apply string sorting while processing, before converting to int values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:14<07:08, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 \t accuracy: 1.0 \t voxels: 10\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:29<06:44, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-1 \t accuracy: 1.0 \t voxels: 765\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:43<06:29, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2 \t accuracy: 1.0 \t voxels: 2766\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:58<06:19, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-3 \t accuracy: 1.0 \t voxels: 1606\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [01:12<06:00, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-4 \t accuracy: 1.0 \t voxels: 1078\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:26<05:45, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-5 \t accuracy: 1.0 \t voxels: 2490\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:41<05:30, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-6 \t accuracy: 1.0 \t voxels: 2011\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [01:55<05:15, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-7 \t accuracy: 1.0 \t voxels: 1641\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [02:10<05:03, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-8 \t accuracy: 1.0 \t voxels: 3035\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [02:24<04:48, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-9 \t accuracy: 1.0 \t voxels: 1538\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [02:38<04:33, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-10 \t accuracy: 1.0 \t voxels: 2955\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [02:53<04:20, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-11 \t accuracy: 1.0 \t voxels: 2201\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [03:08<04:06, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-12 \t accuracy: 1.0 \t voxels: 1610\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [03:22<03:51, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-13 \t accuracy: 1.0 \t voxels: 3391\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [03:37<03:38, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-14 \t accuracy: 1.0 \t voxels: 2070\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [03:51<03:22, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-15 \t accuracy: 1.0 \t voxels: 2085\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [04:05<03:07, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-16 \t accuracy: 1.0 \t voxels: 2376\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [04:19<02:52, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-17 \t accuracy: 1.0 \t voxels: 3352\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [04:34<02:38, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-18 \t accuracy: 1.0 \t voxels: 2032\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [04:50<02:29, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-19 \t accuracy: 1.0 \t voxels: 3230\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [05:05<02:13, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-20 \t accuracy: 1.0 \t voxels: 1977\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [05:19<01:58, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-21 \t accuracy: 1.0 \t voxels: 2926\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [05:34<01:43, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-22 \t accuracy: 1.0 \t voxels: 1893\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [05:49<01:28, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-23 \t accuracy: 1.0 \t voxels: 2501\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [06:04<01:13, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-24 \t accuracy: 1.0 \t voxels: 2499\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [06:18<00:58, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-25 \t accuracy: 1.0 \t voxels: 2319\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [06:32<00:43, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-26 \t accuracy: 1.0 \t voxels: 2670\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [06:47<00:29, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-27 \t accuracy: 0.5 \t voxels: 2663\n",
      "\t multivar. regressor: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [07:01<00:14, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-28 \t accuracy: 1.0 \t voxels: 2057\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [07:16<00:00, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-29 \t accuracy: 1.0 \t voxels: 3493\n",
      "\t multivar. regressor: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9833333333333333, 2241.3333333333335)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "voxels_amounts = []\n",
    "voxels_counts = np.zeros(n_voxels)\n",
    "\n",
    "for i in tqdm(range(k_folds)):\n",
    "\n",
    "    # Extracting filtered (most stable voxels) training set\n",
    "    train_indices = np.array(list(range(samples_per_fold * i)) + list(range((samples_per_fold * (i+1)), n_samples)), dtype=np.int32)\n",
    "    test_indices = np.array(list(range((samples_per_fold * i), samples_per_fold * (i + 1))), dtype=np.int32)\n",
    "\n",
    "    # Building train set\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for word in semantic_features.keys():\n",
    "        if word in fmriData.keys():\n",
    "            x = np.array(semantic_features[word][\"values\"])\n",
    "            y = np.array(fmriData[word])\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = X[train_indices], X[test_indices], Y[train_indices], Y[test_indices]\n",
    "    \n",
    "    # Normalization based on train data\n",
    "    normalizer = StandardScaler()\n",
    "    normalizer.fit(X_train)\n",
    "\n",
    "    X_train = normalizer.transform(X_train)\n",
    "    X_test = normalizer.transform(X_test)\n",
    "\n",
    "    # Predicting & scoring\n",
    "    predictors = [LinearRegression() for i in range(n_voxels)]\n",
    "    voxel_regressor = True\n",
    "    scores = []\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # Fit each voxel predictor\n",
    "    for model in predictors:\n",
    "        model.fit(X_train, y_train[:, j])\n",
    "        scores.append(model.score(X_test, y_test[:, j]))\n",
    "        j += 1\n",
    "\n",
    "    # Select predictors by R2 score and compute 2 words accuracy\n",
    "    scores = np.array(scores)\n",
    "    voxel_indices = np.where(scores > VOXELWISE_ACC_THRESHOLD)[0]\n",
    "    \n",
    "    voxels_amounts.append(voxel_indices.shape[0])\n",
    "    fold_accuracy = voxels_compute_fold_accuracy(predictors, X_test, y_test, voxel_indices)\n",
    "    print(f\"Fold-{i} \\t accuracy: {fold_accuracy} \\t voxels: {len(voxel_indices)}\")\n",
    "    \n",
    "    # With the chosen voxels, fit a multivariate regressor as a test\n",
    "    predictors = Ridge()\n",
    "    predictors.fit(X_train, y_train[:, voxel_indices])\n",
    "    multivar_fold_accuracy = regressor_compute_fold_accuracy(predictors, X_test, y_test[:, voxel_indices])\n",
    "    \n",
    "    print(f\"\\t multivar. regressor: {multivar_fold_accuracy}\")\n",
    "\n",
    "    # Keep track of the chosen voxels\n",
    "    voxels_counts[voxel_indices] += 1\n",
    "\n",
    "    accuracies.append(fold_accuracy)\n",
    "\n",
    "np.mean(accuracies), np.mean(voxels_amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   63,    68,   235,   269,   293,   363,   566,   572,   697,\n",
       "         705,   792,   843,   845,   846,   875,  1108,  1159,  1183,\n",
       "        1256,  1264,  1292,  1460,  1552,  1574,  1662,  1674,  1885,\n",
       "        1895,  1914,  1920,  2007,  2021,  2035,  2053,  2101,  2178,\n",
       "        2226,  2678,  2741,  2949,  3006,  3046,  3049,  3100,  3284,\n",
       "        3357,  3371,  3392,  3935,  3966,  3989,  4023,  4069,  4078,\n",
       "        4155,  4259,  4277,  4326,  4371,  4489,  4507,  4508,  4512,\n",
       "        4513,  4736,  4737,  4738,  4773,  4774,  4776,  4889,  4965,\n",
       "        5082,  5112,  5402,  5605,  5803,  5816,  5825,  6000,  6029,\n",
       "        6212,  6214,  6237,  6299,  6309,  6343,  6475,  6513,  6515,\n",
       "        6516,  6518,  6527,  6540,  6650,  6660,  6665,  6666,  6886,\n",
       "        6891,  6894,  6965,  7070,  7113,  7161,  7162,  7197,  7343,\n",
       "        7389,  7462,  7469,  7740,  7801,  7869,  7883,  7892,  7898,\n",
       "        7994,  8017,  8034,  8170,  8227,  8234,  8237,  8463,  8541,\n",
       "        8553,  8887,  8916,  8918,  8937,  8949,  9055,  9077,  9203,\n",
       "        9258,  9306,  9330,  9424,  9453,  9504,  9535,  9677,  9745,\n",
       "        9947,  9948, 10001, 10030, 10054, 10110, 10186, 10187, 10427,\n",
       "       10461, 10465, 10468, 10641, 10997, 11004, 11032, 11066, 11096,\n",
       "       11151, 11269, 11361, 11413, 11435, 11560, 11831, 11843, 11844,\n",
       "       11858, 11864, 11905, 11906, 11908, 12019, 12208, 12209, 12265,\n",
       "       12281, 12363, 12379, 12522, 12529, 12531, 12646, 12813, 12880,\n",
       "       12926, 12955, 12995, 13028, 13102, 13125, 13155, 13156, 13197,\n",
       "       13210, 13284, 13285, 13324, 13377, 13405, 13699, 13723, 13744,\n",
       "       13792, 13833, 13861, 13884, 13902, 13999, 14005, 14041, 14071,\n",
       "       14084, 14226, 14348, 14391, 14395, 14396, 14409, 14410, 14435,\n",
       "       14693, 14694, 14710, 14847, 14865, 15185, 15205, 15216, 15240,\n",
       "       15294, 15306, 15314, 15438, 15448, 15473, 15502, 15524, 15600,\n",
       "       15619, 15659, 15682, 15718, 15787, 15788, 15948, 15961, 15974,\n",
       "       16001, 16067, 16168, 16217, 16219, 16385, 16419, 16468, 16469,\n",
       "       16470, 16546, 16565, 16625, 16626, 16627, 16656, 16678, 16705,\n",
       "       16725, 16850, 16871, 16963, 17026, 17058, 17092, 17140, 17231,\n",
       "       17290, 17428, 17443, 17492, 17832, 17894, 17908, 18084, 18113,\n",
       "       18198, 18261, 18287, 18318, 18367, 18505, 18593, 18612, 18649,\n",
       "       18687, 19416, 19544, 19596, 19851, 19885, 19920, 19987, 20001,\n",
       "       20027, 20119, 20255, 20349, 20444, 20522, 20594, 20672, 20834,\n",
       "       20853, 20857, 20935, 21203, 21351, 21502, 21666, 21720],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine a subset of voxels that is common across folds and from which we can perform sound multivariate regression\n",
    "VOXELCOUNT_THRESHOLD = 0.25 # voxels that best perform in 20% of folds\n",
    "chosen_voxels = np.where((voxels_counts / k_folds) > VOXELCOUNT_THRESHOLD)[0]\n",
    "chosen_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected voxels\n",
    "predictors = LinearRegression()\n",
    "predictors.fit(X_train, y_train[:, chosen_voxels])\n",
    "multivar_fold_accuracy = regressor_compute_fold_accuracy(predictors, X_test, y_test[:, chosen_voxels])\n",
    "multivar_fold_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL voxels\n",
    "predictors = LinearRegression()\n",
    "predictors.fit(X_train, y_train)\n",
    "multivar_fold_accuracy = regressor_compute_fold_accuracy(predictors, X_test, y_test)\n",
    "multivar_fold_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for omitted_feature in range(embedding_len): \n",
    "    for i in tqdm(range(k_folds)):\n",
    "\n",
    "        # Extracting filtered (most stable voxels) training set\n",
    "        train_indices = np.array(list(range(samples_per_fold * i)) + list(range((samples_per_fold * (i+1)), n_samples)), dtype=np.int32)\n",
    "        test_indices = np.array(list(range((samples_per_fold * i), samples_per_fold * (i + 1))), dtype=np.int32)\n",
    "\n",
    "        # Building train set\n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        for word in semantic_features.keys():\n",
    "            if word in fmriData.keys():\n",
    "                x = np.array([f for k, f in enumerate(semantic_features[word][\"values\"]) if k != omitted_feature])\n",
    "                y = np.array(fmriData[word])\n",
    "\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = X[train_indices], X[test_indices], Y[train_indices], Y[test_indices]\n",
    "        \n",
    "        # Normalization based on train data\n",
    "        normalizer = StandardScaler()\n",
    "        normalizer.fit(X_train)\n",
    "\n",
    "        X_train = normalizer.transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "\n",
    "        # Predicting & scoring\n",
    "        predictors = [LinearRegression() for i in range(n_voxels)]\n",
    "        scores = []\n",
    "\n",
    "        # One predictor per voxel\n",
    "        j = 0\n",
    "        for model in predictors:\n",
    "            model.fit(X_train, y_train[:, j])\n",
    "            scores.append(model.score(X_test, y_test[:, j]))\n",
    "            j += 1\n",
    "        \n",
    "        # Select voxels by R2 score and compute 2 words accuracy\n",
    "        scores = np.array(scores)\n",
    "        voxel_indices = np.where(scores > THRESHOLD)[0]\n",
    "        \n",
    "        voxels_amounts.append(voxel_indices.shape[0])\n",
    "        fold_accuracy = voxels_compute_fold_accuracy(predictors, X_test, y_test, voxel_indices)\n",
    "        \n",
    "        print(f\"Fold-{i} \\t accuracy: {fold_accuracy} \\t voxels: {len(voxel_indices)}\")\n",
    "        accuracies.append(fold_accuracy)\n",
    "\n",
    "    print(f\"Feature omitted: {omitted_feature}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracies)} \\t Voxels: {np.mean(voxels_amounts)}\\n\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "In this case fitting is way more expensive, as 21k voxels are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def best_K_predict(X, indices, predictors):\n",
    "    predictors = [predictors[idx] for idx in indices]\n",
    "    y_hat = np.array([predictor.predict(X) for predictor in predictors]) # voxels, sample\n",
    "    return y_hat.reshape(y_hat.shape[1], y_hat.shape[0]) # sample, voxels\n",
    "\n",
    "# voxel_indices\n",
    "\n",
    "y_hat = best_K_predict(X_train, voxel_indices, predictors)\n",
    "y = y_train[:, voxel_indices]\n",
    "\n",
    "RDM_hat = np.matmul(y_hat, np.matrix.transpose(y_hat))\n",
    "\n",
    "RDM = np.matmul(y, np.matrix.transpose(y))\n",
    "\n",
    "test_pearson = pearsonr(\n",
    "    RDM_hat.flatten(),\n",
    "    RDM.flatten()\n",
    ")\n",
    "\n",
    "print(f\"Test RDMs R^2:\\t{test_pearson}\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Truth\")\n",
    "plt.imshow(RDM)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Prediction\")\n",
    "plt.imshow(RDM_hat)\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Here the the voxels from the last cross_val iteration have been selected. For these voxels, the object to object distance matrices have similar patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
